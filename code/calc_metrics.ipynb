{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib import RDF\n",
    "from rdflib import URIRef\n",
    "from rdflib import Literal\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from rdflib.plugins.stores.sparqlstore import SPARQLStore\n",
    "from queries import QUERY_AI, QUERY_FILM, QUERY_PERSON\n",
    "from paths_to_examples import REPO_BOOKS, REPO_PEOPLE, WIKIDATA, GPT_EX, GPT_SUBCLASSES\n",
    "\n",
    "DEBUG = True  # for debug prints\n",
    "PRINTGRAPH = False # for showing the networkX graph\n",
    "LOCAL = True # for choosing local ttl file path or SPARQL endpoint \n",
    "\n",
    "def debug_print(*args, **kwargs):\n",
    "    if DEBUG:\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "\n",
    "# printing all elements of a set\n",
    "def print_set(set):\n",
    "    if DEBUG:\n",
    "        for i in set:\n",
    "            print(i)\n",
    "\n",
    "def show_graph(G):\n",
    "    if PRINTGRAPH:\n",
    "        # calculating positions for nodes\n",
    "        pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "\n",
    "        # printing nodes and edges\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", node_size=1500, font_size=10, font_weight=\"bold\", arrows=True)\n",
    "\n",
    "        # printing labels for the edges\n",
    "        edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red')\n",
    "\n",
    "        plt.title(\"RDF Graph\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"FINISHED PRINTING GRAPH\\n\\n\")        \n",
    "\n",
    "# Calculating all paths from one root node (start node)\n",
    "def find_all_paths(G, start_node):\n",
    "    # helper function for DFS\n",
    "    def dfs(node, path):\n",
    "        global num_paths\n",
    "        global abs_depth\n",
    "        global max_depth\n",
    "\n",
    "        # skip node if it already is in path (avoiding cycles)\n",
    "        if node in path:\n",
    "            return\n",
    "        \n",
    "        # add current node to path\n",
    "        path.append(node)\n",
    "        \n",
    "        neighbors = list(G.neighbors(node))\n",
    "        # if node does not have any neighbors left, there is no other path left\n",
    "        if not neighbors:\n",
    "            paths.append(list(path))  # Store current path\n",
    "            num_paths += 1\n",
    "            abs_depth += (len(path) - 1) # cardinality of a path = number of EDGES in path (=> -1)\n",
    "            if (len(path)-1) > max_depth:\n",
    "                max_depth = len(path) - 1\n",
    "        \n",
    "        # recursively extend the path for each neighbor\n",
    "        for neighbor in neighbors:\n",
    "            dfs(neighbor, path)\n",
    "        \n",
    "        # remove node from the path to find next path\n",
    "        path.pop()\n",
    "\n",
    "    # list which stores all paths\n",
    "    paths = []\n",
    "    \n",
    "    # starts DFS with start_node\n",
    "    dfs(start_node, [])\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c19b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to ttl file\n",
    "# can also be an online graph source\n",
    "ttl_file_path = REPO_BOOKS\n",
    "g = Graph()\n",
    "\n",
    "print(\"STARTING PARSING\")\n",
    "\n",
    "if LOCAL == True:\n",
    "    # if it fails -> print some error\n",
    "    try:\n",
    "        g.parse(ttl_file_path, format=\"turtle\")\n",
    "    except Exception as e:\n",
    "        print(\"ERROR WHILE PARSING GRAPH: {e}\")\n",
    "\n",
    "else:\n",
    "\n",
    "    endpoint_url = \"https://dbpedia.org/sparql\"\n",
    "    store = SPARQLStore()\n",
    "    store.open(endpoint_url)\n",
    "\n",
    "    g_remote = Graph(store=store)\n",
    "\n",
    "    query = QUERY_AI\n",
    "\n",
    "    g += g_remote.query(query).graph\n",
    "    \n",
    "\n",
    "print(\"Number of triples: \" + str(len(g)))    \n",
    "print(\"FINISHED PARSING\\n\")\n",
    "\n",
    "#for s, p, o in g:\n",
    " #   print(s, p, o)\n",
    "\n",
    "print(\"STARTING GETTING ROOT NODES AND LITERALS\")\n",
    "\n",
    "all_nodes = set(g.subjects())\n",
    "\n",
    "# printing all subject nodes\n",
    "# print_set(nodes)\n",
    "\n",
    "# all objects\n",
    "object_nodes = set(g.objects())\n",
    "\n",
    "# all literals in a graph (literals can only appear as objects)\n",
    "literals = set(o for o in object_nodes if isinstance(o, Literal))\n",
    "\n",
    "# converting items of literals to strings\n",
    "literals = {str(item) for item in literals}\n",
    "\n",
    "# getting possible root nodes\n",
    "root_nodes = all_nodes - object_nodes\n",
    "\n",
    "debug_print(\"Root Nodes:\")\n",
    "print_set(root_nodes)\n",
    "#debug_print(\"\\n\")\n",
    "\n",
    "print(\"FINISHED GETTING ROOT NODES AND LITERALS\\n\")\n",
    "\n",
    "print(\"STARTING CREATING GRAPH G\")\n",
    "\n",
    "# NetworkX-DiGraph for visualization\n",
    "G = nx.DiGraph()\n",
    "\n",
    "debug_print(\"Printing all triples:\")\n",
    "# add triples to GRaph G\n",
    "for subj, pred, obj in g:\n",
    "    G.add_edge(str(subj), str(obj), label=str(pred))\n",
    "    debug_print(\"(\" , subj, \",\", pred, \",\", obj, \")\")\n",
    "\n",
    "print(\"FINISHED CREATING GRAPH G\\n\")\n",
    "\n",
    "show_graph(G)\n",
    "\n",
    "num_paths = 0\n",
    "abs_depth = 0\n",
    "max_depth = 0\n",
    "\n",
    "print(\"STARTING CALCULATING PATHS\")\n",
    "\n",
    "# list of paths for all root nodes\n",
    "all_paths = {}\n",
    "\n",
    "# calculating all paths from root nodes\n",
    "for root in list(root_nodes):\n",
    "    str_root = str(root)\n",
    "    debug_print(\"Starting searching for paths with root node: \" + str_root)\n",
    "    all_paths[str_root] = find_all_paths(G, str_root)\n",
    "\n",
    "print(\"FINISHED CALCULATING PATHS\\n\")\n",
    "\n",
    "# Output root node + found paths\n",
    "# print(\"FOUND PATHS:\")\n",
    "# for root_node, paths in all_paths.items():\n",
    "#     print(f\"Root-Knoten: {root_node}\")\n",
    "#     for path in paths:\n",
    "#         print(path)\n",
    "\n",
    "# Output found paths\n",
    "print(\"FOUND PATHS:\")\n",
    "for root_node, paths in all_paths.items():\n",
    "    for path in paths:\n",
    "        print(path)\n",
    "        print(\"Path length = \" + str(len(path)-1))\n",
    "        \n",
    "\n",
    "#num_paths = len(all_paths)\n",
    "\n",
    "print(\"RESULTS:\")\n",
    "\n",
    "print(\"-Number of Paths: \" + str(num_paths))\n",
    "print(\"-Absolute depth: \" + str(abs_depth))\n",
    "\n",
    "avg_depth = abs_depth / num_paths\n",
    "\n",
    "print(\"-Average depth: \" + str(avg_depth))\n",
    "print(\"-Maximal depth: \" + str(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce36f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in graph: 2\n",
      "Number of classes with more than one superclass: 0\n",
      "t: 0\n",
      "\n",
      "Classes with more than one superclass: \n",
      "0 nodes\n",
      "\n",
      "RESULT:\n",
      "-Tangledness: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Tangledness \n",
    "# source 73 - page 4\n",
    "# tangledness = mean number of classes with more than 1 direct ancestor, so two primitive \n",
    "# measurements (number of classes and number of direct ancestors) are used for computing the metric \n",
    "\n",
    "# Select number of classes in graph \n",
    "query = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "\n",
    "SELECT (COUNT(DISTINCT ?class) AS ?num_classes)\n",
    "WHERE {\n",
    "  {\n",
    "    # 1. explicitly/implicitly used RDF classes\n",
    "    # explicitly: ?class a owl:Class . or ?class a rdfs:Class .\n",
    "    # implicitly: ?any rdf:type ?class . (includes also explicitly used classes)\n",
    "\n",
    "    ?any rdf:type ?class .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 2. subclasses\n",
    "    ?class rdfs:subClassOf ?any .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 3. superclasses\n",
    "    ?any rdfs:subClassOf ?class .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 4. classes used with owl:equivalentClass\n",
    "    { ?class owl:equivalentClass ?any . }\n",
    "    UNION\n",
    "    { ?any owl:equivalentClass ?class . }\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 5. OWL restriction classes\n",
    "    ?class a owl:Restriction .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 6. complex classes with using unionOf, intersectionOf etc.\n",
    "    ?class owl:unionOf|owl:intersectionOf|owl:complementOf|owl:oneOf ?list .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 7. OWL hasValue restrictions\n",
    "    ?class owl:hasValue ?val .\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "res = g.query(query)\n",
    "for row in res:\n",
    "    print(\"Number of classes in graph: \" + str(row['num_classes']))\n",
    "    num_classes = int(row['num_classes'])\n",
    "\n",
    "# Select number of classes with more than one ingoing isA arc (Dr. Jovanovik said I should use is-a)\n",
    "query_var1 = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "SELECT (COUNT(?class) AS ?tangledCount)\n",
    "WHERE\n",
    "{\n",
    "  SELECT ?class (COUNT(?s) AS ?numIngoing)\n",
    "  WHERE {\n",
    "    { ?s rdf:type ?class . }\n",
    "  }\n",
    "  GROUP BY ?class\n",
    "  HAVING (COUNT(?s) > 1) # problem here was: i used ?numIngoing instead of COUNT(?s)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Select number of classes with more than one superclass (source says I should use this query)\n",
    "query_var2 = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "SELECT (COUNT(?class) AS ?tangledCount)\n",
    "WHERE {\n",
    "  SELECT ?class (COUNT(?super) AS ?numSupers)\n",
    "  WHERE {\n",
    "    ?class rdfs:subClassOf ?super .\n",
    "  }\n",
    "  GROUP BY ?class\n",
    "  HAVING (COUNT(?super) > 1)\n",
    "}\n",
    "\"\"\"\n",
    "res = g.query(query_var2)\n",
    "\n",
    "for row in res:\n",
    "  print(\"Number of classes with more than one superclass: \" + str(row[\"tangledCount\"]) )\n",
    "  t = int(row[\"tangledCount\"])\n",
    "  #print(\"Class \" + str(row[\"class\"]) + \": \" + str(row[\"numIngoing\"]))\n",
    "\n",
    "print(\"t: \" + str(t))\n",
    "\n",
    "debug_print(\"\\nClasses with more than one superclass: \")\n",
    "\n",
    "if DEBUG:\n",
    "  if t == 0:\n",
    "    debug_print(\"0 nodes\")\n",
    "  else:\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT ?class (COUNT(?s) AS ?numIngoing)\n",
    "    WHERE {\n",
    "      { ?s rdf:type ?class . }\n",
    "      UNION\n",
    "      { ?s a ?class . }  \n",
    "    }\n",
    "    GROUP BY ?class\n",
    "    HAVING (COUNT(?s) > 1)\n",
    "    \"\"\"\n",
    "\n",
    "    res = g.query(query)\n",
    "\n",
    "    for row in res:\n",
    "        debug_print(\"Class: \" + str(row[\"class\"]) + \" - TangledCount: \" + str(row[\"numIngoing\"]))\n",
    "\n",
    "print(\"\\nRESULT:\")\n",
    "\n",
    "if num_classes > 0:\n",
    "  # source 37 says num_classes / t\n",
    "  # source 73 says denominator and numerator should be switched -> t / num_classes\n",
    "  tangledness = num_classes / t\n",
    "  print(\"-Tangledness: \" + str(tangledness))\n",
    "else:\n",
    "  # TODO\n",
    "   print(\"-Tangledness is INF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392799b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree Distribution (Formula in: source 37, page 7)\n",
    "# nG...number of nodes in gaph\n",
    "# nE...number of edges in graph\n",
    "\n",
    "# Calculating nE\n",
    "query = \"\"\"\n",
    "SELECT (COUNT(*) AS ?tripleCount)\n",
    "WHERE {\n",
    "  ?s ?p ?o .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "res = g.query(query)\n",
    "for row in res:\n",
    "    print(\"Number of edges in graph: \" + str(row['tripleCount']))\n",
    "    nE = int(row['tripleCount'])\n",
    "\n",
    "# Calculating nG\n",
    "query = \"\"\"\n",
    "SELECT (COUNT(DISTINCT ?node) AS ?nodeCount)\n",
    "WHERE {\n",
    "  {\n",
    "    SELECT ?node WHERE {\n",
    "      { ?node ?p1 ?o }       \n",
    "      UNION\n",
    "      { ?s ?p2 ?node }       \n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "res = g.query(query)\n",
    "for row in res:\n",
    "    print(\"Number of nodes in graph: \" + str(row['nodeCount']))\n",
    "    nG = int(row['nodeCount'])\n",
    "\n",
    "# Calculating degree for every node in graph\n",
    "query = \"\"\"\n",
    "SELECT ?node (COUNT(?any) AS ?degree)\n",
    "WHERE {\n",
    "  {\n",
    "    { ?node ?p1 ?any }     # Outgoing edges\n",
    "    UNION\n",
    "    { ?any ?p2 ?node }     # Incoming edges\n",
    "  }\n",
    "}\n",
    "GROUP BY ?node\n",
    "\"\"\"\n",
    "\n",
    "# sum_of_degress = 0\n",
    "degrees = []\n",
    "\n",
    "res = g.query(query)\n",
    "for row in res:\n",
    "    debug_print(\"Node: \" + str(row['node']) + \" - Degree: \" + str(row['degree']))\n",
    "    #sum_of_degress += int(row['degree'])\n",
    "    degrees.append(int(row['degree']))\n",
    "   \n",
    "print(\"\\nSum of Degrees: \" + str(sum(degrees)))\n",
    "\n",
    "if nG > 1:\n",
    "    mean_degree = (2 * nE) / nG\n",
    "    squared_diffs = [(deg_v - mean_degree) ** 2 for deg_v in degrees]\n",
    "    degree_distribution = sum(squared_diffs) / (nG-1)\n",
    "else:\n",
    "    degree_distribution = 0 \n",
    "\n",
    "print(\"\\nRESULT:\")\n",
    "print(\"-Degree Distribution: \" + str(degree_distribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of instances per type\n",
    "query = \"\"\" SELECT ?type (COUNT(?s) AS ?count)\n",
    "WHERE {\n",
    "  ?s rdf:type ?type . \n",
    "}\n",
    "GROUP BY ?type \"\"\"\n",
    "\n",
    "res = g.query(query)\n",
    "\n",
    "num_instances = 0\n",
    "\n",
    "for row in res:\n",
    "    debug_print(\"Number of instancees of\", str(row[\"type\"]), \": \" ,  str(row[\"count\"]) )\n",
    "    num_instances += int(row[\"count\"])\n",
    "\n",
    "# Number of classes\n",
    "# Defintion of Class: \n",
    "# source: 213, page: 5 - source: 250, page: 3\n",
    "# TNOC (total number of classes/concepts) = classes, subclasses, superclasses, anonymous classes\n",
    "# anonymous classes = equivalent/restriction/unionOf/intersectionOf/complementOf/oneOf/hasValue classes\n",
    "\n",
    "query = \"\"\" \n",
    "SELECT DISTINCT ?class\n",
    "WHERE {\n",
    "  {\n",
    "    # 1. explicitly/implicitly used RDF classes\n",
    "    # explicitly: ?class a owl:Class . or ?class a rdfs:Class .\n",
    "    # implicitly: ?any rdf:type ?class . (includes also explicitly used classes)\n",
    "\n",
    "    ?any rdf:type ?class .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 2. subclasses\n",
    "    ?class rdfs:subClassOf ?any .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 3. superclasses\n",
    "    ?any rdfs:subClassOf ?class .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 4. classes used with owl:equivalentClass\n",
    "    { ?class owl:equivalentClass ?any . }\n",
    "    UNION\n",
    "    { ?any owl:equivalentClass ?class . }\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 5. OWL restriction classes\n",
    "    ?class a owl:Restriction .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 6. complex classes with using unionOf, intersectionOf etc.\n",
    "    ?class owl:unionOf|owl:intersectionOf|owl:complementOf|owl:oneOf ?list .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    # 7. OWL hasValue restrictions\n",
    "    ?class owl:hasValue ?val .\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "res = g.query(query)\n",
    "\n",
    "num_classes = 0\n",
    "\n",
    "debug_print(\"\\nExisting classes: \")\n",
    "\n",
    "for row in res:\n",
    "  debug_print(\"Class \" + str(num_classes+1) + \": \" + str(row[\"class\"]))\n",
    "  num_classes += 1\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "print(\"-Number of instances:\", num_instances)\n",
    "print(\"-Number of classes:\", num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
